import warnings
warnings.filterwarnings('ignore')
import os
import json
import torch
import numpy as np
import argparse
import joblib

# å¯¼å…¥æ¨¡å‹å®šä¹‰å’Œæ•°æ®å¤„ç†å™¨
from utils import models
from utils.dataset_prepare import DataProcessor

def create_sample_raw_input(raw_input=None):
    """
    ä¸ºæ¼”ç¤ºå’ŒéªŒè¯ç›®çš„,åˆ›å»ºä¸€ä¸ªç¬¦åˆç‰©ç†èŒƒå›´çš„ã€æœªç»å¤„ç†çš„åŸå§‹è¾“å…¥æ ·æœ¬ã€‚
    è¿™æ¨¡æ‹Ÿäº†åœ¨å®é™…æ¨ç†åœºæ™¯ä¸­,æ¨¡å‹æ¥å£æ¥æ”¶åˆ°çš„åŸå§‹æ•°æ®ã€‚
    
    è¾“å…¥:
        raw_input (dict, tuple or None): 
            - å¦‚æœæ˜¯å­—å…¸: åŒ…å«å‚æ•°åå’Œå¯¹åº”å€¼çš„å­—å…¸,æ”¯æŒçš„é”®åŒ…æ‹¬:
                'impact_velocity', 'impact_angle', 'overlap', 'occupant_type',
                'll1', 'll2', 'btf', 'pp', 'plp', 'lla_status', 'llattf', 
                'dz', 'ptf', 'aft', 'aav_status', 'ttf', 'sp', 'recline_angle',
                'waveform' (å½¢çŠ¶ä¸º (3, 150) çš„ç¢°æ’æ³¢å½¢)
              ç¼ºå¤±æˆ–ä¸åˆè§„çš„å‚æ•°å°†è¢«éšæœºç”Ÿæˆã€‚
            - å¦‚æœæ˜¯å…ƒç»„: æ ¼å¼ä¸º (raw_params, raw_waveform)
                - raw_params (np.ndarray): å½¢çŠ¶ä¸º (18,) çš„åŸå§‹æ ‡é‡ç‰¹å¾ã€‚
                - raw_waveform (np.ndarray): å½¢çŠ¶ä¸º (3, 150) çš„åŸå§‹ç¢°æ’æ³¢å½¢ã€‚
            - å¦‚æœä¸º None: åˆ™éšæœºç”Ÿæˆå®Œæ•´æ ·æœ¬ã€‚

    è¿”å›:
        tuple: (raw_params, raw_waveform)
        - raw_params (np.ndarray): å½¢çŠ¶ä¸º (18,) çš„åŸå§‹æ ‡é‡ç‰¹å¾,float32ç±»å‹ã€‚
                                   é¡ºåºä¸data_package.pyä¸­å®šä¹‰çš„ä¸€è‡´ã€‚
        - raw_waveform (np.ndarray): å½¢çŠ¶ä¸º (3, 150) çš„åŸå§‹ç¢°æ’æ³¢å½¢,float32ç±»å‹ã€‚
                                     é€šé“é¡ºåºä¸º [X, Y, Z]ã€‚
    """
    
    # å®šä¹‰å‚æ•°åç§°ä¸ç´¢å¼•çš„æ˜ å°„
    param_names = [
        'impact_velocity', 'impact_angle', 'overlap', 'occupant_type',
        'll1', 'll2', 'btf', 'pp', 'plp', 'lla_status', 'llattf',
        'dz', 'ptf', 'aft', 'aav_status', 'ttf', 'sp', 'recline_angle'
    ]
    
    # å®šä¹‰å‚æ•°éªŒè¯å’Œç”Ÿæˆè§„åˆ™
    def validate_and_generate(key, value, raw_params):
        """éªŒè¯å‚æ•°å¹¶åœ¨ä¸åˆè§„æ—¶ç”Ÿæˆéšæœºå€¼"""
        try:
            if key == 'impact_velocity':
                val = float(value)
                return val if 25 <= val <= 65 else np.random.uniform(25, 65)
            
            elif key == 'impact_angle':
                val = float(value)
                return val if -45 <= val <= 45 else np.random.uniform(-45, 45)
            
            elif key == 'overlap':
                val = float(value)
                if (-1 <= val <= -0.25) or (0.25 <= val < 1):
                    return val
                else:
                    return np.random.uniform(0.25, 1.0) if np.random.rand() > 0.5 else np.random.uniform(-1.0, -0.25)
            
            elif key == 'occupant_type':
                val = int(value)
                return val if val in [1, 2, 3] else np.random.choice([1, 2, 3])
            
            elif key == 'll1':
                val = float(value)
                return val if 2.0 <= val <= 7.0 else np.random.uniform(2.0, 7.0)
            
            elif key == 'll2':
                val = float(value)
                return val if 1.5 <= val <= 4.5 else np.random.uniform(1.5, 4.5)
            
            elif key == 'btf':
                val = float(value)
                return val if 10 <= val <= 100 else np.random.uniform(10, 100)
            
            elif key == 'pp':
                val = float(value)
                return val if 40 <= val <= 100 else np.random.uniform(40, 100)
            
            elif key == 'plp':
                val = float(value)
                return val if 20 <= val <= 80 else np.random.uniform(20, 80)
            
            elif key == 'lla_status':
                val = int(value)
                return val if val in [0, 1] else np.random.choice([0, 1])
            
            elif key == 'llattf':
                val = float(value)
                if raw_params[9] == 1:  # lla_status == 1
                    return val if val >= raw_params[6] else raw_params[6] + np.random.uniform(0, 100)
                else:
                    return 0
            
            elif key == 'dz':
                val = int(value)
                return val if val in [1, 2, 3, 4] else np.random.choice([1, 2, 3, 4])
            
            elif key == 'ptf':
                val = float(value)
                # ptf é€šå¸¸ä¸º btf + 7
                return val if abs(val - (raw_params[6] + 7)) < 20 else raw_params[6] + 7
            
            elif key == 'aft':
                val = float(value)
                return val if 10 <= val <= 100 else np.random.uniform(10, 100)
            
            elif key == 'aav_status':
                val = int(value)
                return val if val in [0, 1] else np.random.choice([0, 1])
            
            elif key == 'ttf':
                val = float(value)
                if raw_params[14] == 1:  # aav_status == 1
                    return val if val >= raw_params[13] else raw_params[13] + np.random.uniform(0, 100)
                else:
                    return 0
            
            elif key == 'sp':
                val = float(value)
                occupant_type = raw_params[3]
                if occupant_type == 1 and 10 <= val <= 110:
                    return val
                elif occupant_type == 2 and -80 <= val <= 80:
                    return val
                elif occupant_type == 3 and -110 <= val <= 40:
                    return val
                else:
                    # æ ¹æ®occupant_typeç”Ÿæˆ
                    if occupant_type == 1:
                        return np.random.uniform(10, 110)
                    elif occupant_type == 2:
                        return np.random.uniform(-80, 80)
                    else:
                        return np.random.uniform(-110, 40)
            
            elif key == 'recline_angle':
                val = float(value)
                return val if -10 <= val <= 15 else np.random.uniform(-10, 15)
            
        except (ValueError, TypeError):
            # ç±»å‹è½¬æ¢å¤±è´¥,è¿”å›Noneè§¦å‘éšæœºç”Ÿæˆ
            return None
        
        return None
    
    # åˆå§‹åŒ–å‚æ•°æ•°ç»„
    raw_params = np.zeros(18, dtype=np.float32)
    
    # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
    if raw_input is None:
        print("  âš  æœªæä¾›åŸå§‹è¾“å…¥,ä½¿ç”¨éšæœºç”Ÿæˆçš„æ ·æœ¬è¿›è¡Œæ¼”ç¤ºå’ŒéªŒè¯ã€‚")
        input_dict = {}
    elif isinstance(raw_input, dict):
        print("  ğŸ“¥ ä»å­—å…¸è¯»å–è¾“å…¥å‚æ•°...")
        input_dict = raw_input
    elif isinstance(raw_input, tuple) and len(raw_input) == 2:
        # å…¼å®¹åŸæœ‰çš„å…ƒç»„è¾“å…¥æ ¼å¼
        print("  ğŸ“¥ ä»å…ƒç»„è¯»å–è¾“å…¥å‚æ•°...")
        return raw_input[0].astype(np.float32), raw_input[1].astype(np.float32)
    else:
        print("  âš  è¾“å…¥æ ¼å¼ä¸æ­£ç¡®,ä½¿ç”¨éšæœºç”Ÿæˆçš„æ ·æœ¬ã€‚")
        input_dict = {}
    
    # æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªå‚æ•°
    for idx, key in enumerate(param_names):
        if key in input_dict:
            validated_value = validate_and_generate(key, input_dict[key], raw_params)
            if validated_value is not None:
                raw_params[idx] = validated_value
                print(f"    âœ“ {key}: ä½¿ç”¨æä¾›çš„å€¼ {validated_value:.4f}")
            else:
                # éªŒè¯å¤±è´¥,éšæœºç”Ÿæˆ
                raw_params[idx] = validate_and_generate(key, None, raw_params) or 0
                print(f"    âš  {key}: æä¾›å€¼ä¸åˆè§„,å·²éšæœºç”Ÿæˆ {raw_params[idx]:.4f}")
        else:
            # å‚æ•°ç¼ºå¤±,éšæœºç”Ÿæˆ
            if key == 'impact_velocity':
                raw_params[idx] = np.random.uniform(25, 65)
            elif key == 'impact_angle':
                raw_params[idx] = np.random.uniform(-45, 45)
            elif key == 'overlap':
                raw_params[idx] = np.random.uniform(0.25, 1.0) if np.random.rand() > 0.5 else np.random.uniform(-1.0, -0.25)
            elif key == 'occupant_type':
                raw_params[idx] = np.random.choice([1, 2, 3])
            elif key == 'll1':
                raw_params[idx] = np.random.uniform(2.0, 7.0)
            elif key == 'll2':
                raw_params[idx] = np.random.uniform(1.5, 4.5)
            elif key == 'btf':
                raw_params[idx] = np.random.uniform(10, 100)
            elif key == 'pp':
                raw_params[idx] = np.random.uniform(40, 100)
            elif key == 'plp':
                raw_params[idx] = np.random.uniform(20, 80)
            elif key == 'lla_status':
                raw_params[idx] = np.random.choice([0, 1])
            elif key == 'llattf':
                raw_params[idx] = raw_params[6] + np.random.uniform(0, 100) if raw_params[9] == 1 else 0
            elif key == 'dz':
                raw_params[idx] = np.random.choice([1, 2, 3, 4])
            elif key == 'ptf':
                raw_params[idx] = raw_params[6] + 7
            elif key == 'aft':
                raw_params[idx] = np.random.uniform(10, 100)
            elif key == 'aav_status':
                raw_params[idx] = np.random.choice([0, 1])
            elif key == 'ttf':
                raw_params[idx] = raw_params[13] + np.random.uniform(0, 100) if raw_params[14] == 1 else 0
            elif key == 'sp':
                if raw_params[3] == 1:
                    raw_params[idx] = np.random.uniform(10, 110)
                elif raw_params[3] == 2:
                    raw_params[idx] = np.random.uniform(-80, 80)
                else:
                    raw_params[idx] = np.random.uniform(-110, 40)
            elif key == 'recline_angle':
                raw_params[idx] = np.random.uniform(-10, 15)
            
            print(f"    âš  {key}: æœªæä¾›,å·²éšæœºç”Ÿæˆ {raw_params[idx]:.4f}")
    
    # å¤„ç†æ³¢å½¢æ•°æ®
    if 'waveform' in input_dict:
        try:
            waveform = np.array(input_dict['waveform'], dtype=np.float32)
            if waveform.shape == (3, 150):
                raw_waveform = waveform
                print("    âœ“ waveform: ä½¿ç”¨æä¾›çš„æ³¢å½¢æ•°æ®")
            else:
                print(f"    âš  waveform: å½¢çŠ¶ä¸æ­£ç¡® {waveform.shape},æœŸæœ› (3, 150),å·²éšæœºç”Ÿæˆ")
                x_wave = -np.abs(np.random.randn(150) * 300 + 100)
                y_wave = np.random.randn(150) * 40
                z_wave = np.random.randn(150) * 20
                raw_waveform = np.stack([x_wave, y_wave, z_wave], axis=0).astype(np.float32)
        except Exception as e:
            print(f"    âš  waveform: è§£æå¤±è´¥ ({e}),å·²éšæœºç”Ÿæˆ")
            x_wave = -np.abs(np.random.randn(150) * 300 + 100)
            y_wave = np.random.randn(150) * 40
            z_wave = np.random.randn(150) * 20
            raw_waveform = np.stack([x_wave, y_wave, z_wave], axis=0).astype(np.float32)
    else:
        print("    âš  waveform: æœªæä¾›,å·²éšæœºç”Ÿæˆ")
        x_wave = -np.abs(np.random.randn(150) * 300 + 100)
        y_wave = np.random.randn(150) * 40
        z_wave = np.random.randn(150) * 20
        raw_waveform = np.stack([x_wave, y_wave, z_wave], axis=0).astype(np.float32)
    
    return raw_params, raw_waveform

def preprocess_input(raw_params, raw_waveform, processor):
    """
    ä½¿ç”¨åŠ è½½çš„DataProcessorå¯¹åŸå§‹è¾“å…¥æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿å…¶ç¬¦åˆæ¨¡å‹è¾“å…¥è¦æ±‚ã€‚

    Args:
        raw_params (np.ndarray): å½¢çŠ¶ä¸º (18,) çš„åŸå§‹æ ‡é‡ç‰¹å¾ã€‚
        raw_waveform (np.ndarray): å½¢çŠ¶ä¸º (3, 150) çš„åŸå§‹ç¢°æ’æ³¢å½¢ã€‚
        processor (DataProcessor): å·²ä»'preprocessors.joblib'åŠ è½½çš„ã€æ‹Ÿåˆå¥½çš„å¤„ç†å™¨å¯¹è±¡ã€‚

    Returns:
        tuple: (x_acc, x_att_continuous, x_att_discrete)
        - x_acc (torch.Tensor): å½¢çŠ¶ä¸º (1, 3, 150) çš„å¤„ç†åæ³¢å½¢å¼ é‡ã€‚
        - x_att_continuous (torch.Tensor): å½¢çŠ¶ä¸º (1, 14) çš„å¤„ç†åè¿ç»­æ ‡é‡å¼ é‡ã€‚
        - x_att_discrete (torch.Tensor): å½¢çŠ¶ä¸º (1, 4) çš„å¤„ç†åç¦»æ•£æ ‡é‡å¼ é‡, longç±»å‹ã€‚
    """
    # --- 1. æ³¢å½¢é¢„å¤„ç† ---
    # ä½¿ç”¨åœ¨è®­ç»ƒé›†ä¸Šå­¦ä¹ åˆ°çš„å…¨å±€å› å­è¿›è¡Œå½’ä¸€åŒ–
    waveform_processed = raw_waveform / processor.waveform_norm_factor
    
    # --- 2. æ ‡é‡ç‰¹å¾é¢„å¤„ç† ---
    # å°†åŸå§‹è¾“å…¥é‡å¡‘ä¸º (1, 18) ä»¥åŒ¹é…scalerå’Œencoderçš„è¾“å…¥è¦æ±‚
    params_reshaped = raw_params.reshape(1, -1)
    
    # æå–è¿ç»­å’Œç¦»æ•£ç‰¹å¾
    continuous_raw = params_reshaped[:, processor.continuous_indices]
    discrete_raw = params_reshaped[:, processor.discrete_indices]
    
    # ä½¿ç”¨åŠ è½½çš„scalerè½¬æ¢è¿ç»­ç‰¹å¾
    continuous_processed = np.zeros_like(continuous_raw, dtype=np.float32)
    continuous_processed[:, processor.minmax_indices_in_continuous] = processor.scaler_minmax.transform(continuous_raw[:, processor.minmax_indices_in_continuous])
    continuous_processed[:, processor.maxabs_indices_in_continuous] = processor.scaler_maxabs.transform(continuous_raw[:, processor.maxabs_indices_in_continuous])
    
    # ä½¿ç”¨åŠ è½½çš„encoderè½¬æ¢ç¦»æ•£ç‰¹å¾
    discrete_processed = np.zeros_like(discrete_raw, dtype=np.int64)
    for i in range(discrete_raw.shape[1]):
        # å¯¹æ¯ä¸ªç¦»æ•£ç‰¹å¾åˆ—è¿›è¡Œè½¬æ¢
        discrete_processed[:, i] = processor.encoders_discrete[i].transform(discrete_raw[:, i])

    # --- 3. è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶å¢åŠ batchç»´åº¦ ---
    x_acc = torch.tensor(waveform_processed, dtype=torch.float32).unsqueeze(0)
    x_att_continuous = torch.tensor(continuous_processed, dtype=torch.float32)
    x_att_discrete = torch.tensor(discrete_processed, dtype=torch.long)
    
    return x_acc, x_att_continuous, x_att_discrete

def export_model(model, sample_inputs, output_path, model_type="teacher", opset_version=17):
    """
    å°†PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼ã€‚

    Args:
        model (torch.nn.Module): å¾…å¯¼å‡ºçš„PyTorchæ¨¡å‹ã€‚
        sample_inputs (tuple): ç”¨äºè¿½è¸ªæ¨¡å‹å›¾çš„æ ·æœ¬è¾“å…¥å¼ é‡ã€‚
        output_path (str): ONNXæ–‡ä»¶çš„ä¿å­˜è·¯å¾„ã€‚
        model_type (str): æ¨¡å‹ç±»å‹, 'teacher' æˆ– 'student'ã€‚
        opset_version (int): ONNXç®—å­é›†ç‰ˆæœ¬ã€‚
    """
    if model_type == "teacher":
        input_names = ["x_acc", "x_att_continuous", "x_att_discrete"]
        model_inputs = sample_inputs
    else: # student
        input_names = ["x_att_continuous", "x_att_discrete"]
        _, x_att_continuous, x_att_discrete = sample_inputs
        model_inputs = (x_att_continuous, x_att_discrete)

    output_names = ["predictions", "encoder_output", "decoder_output"]
    
    # å®šä¹‰è¾“å…¥çš„åŠ¨æ€è½´ï¼Œå…è®¸batch_sizeå¯å˜
    dynamic_axes = {name: {0: "batch_size"} for name in input_names + output_names}

    torch.onnx.export(
        model,
        model_inputs,
        output_path,
        input_names=input_names,
        output_names=output_names,
        dynamic_axes=dynamic_axes,
        do_constant_folding=True,
        opset_version=opset_version,
    )
    print(f"âœ” {model_type.capitalize()} æ¨¡å‹å·²å¯¼å‡ºè‡³: {output_path}")

    # ç®€åŒ–ONNXæ¨¡å‹
    try:
        import onnx
        from onnxsim import simplify
        print("  æ­£åœ¨ç®€åŒ–ONNXæ¨¡å‹...")
        onnx_model = onnx.load(output_path)
        model_simp, check = simplify(onnx_model)
        if check:
            onnx.save(model_simp, output_path)
            print("  âœ” ONNXæ¨¡å‹ç®€åŒ–å®Œæˆ")
        else:
            print("  âœ˜ ONNXæ¨¡å‹ç®€åŒ–éªŒè¯å¤±è´¥ï¼Œä¿ç•™åŸæ¨¡å‹")
    except ImportError:
        print("  âš  æœªå®‰è£…onnx-simplifierï¼Œè·³è¿‡ç®€åŒ–æ­¥éª¤")

def verify_onnx_model(onnx_path, pytorch_model, sample_inputs, model_type="teacher"):
    """
    ä½¿ç”¨ONNX RuntimeéªŒè¯å¯¼å‡ºæ¨¡å‹çš„è¾“å‡ºæ˜¯å¦ä¸PyTorchæ¨¡å‹ä¸€è‡´ã€‚
    """
    try:
        import onnxruntime as ort
    except ImportError:
        print("  âš  æœªå®‰è£…onnxruntimeï¼Œè·³è¿‡éªŒè¯æ­¥éª¤ã€‚å¯è¿è¡Œ 'pip install onnxruntime'")
        return
    
    print(f"\n========== éªŒè¯ {model_type.capitalize()} ONNX æ¨¡å‹ ==========")
    
    # --- PyTorch æ¨ç† ---
    pytorch_model.eval()
    with torch.no_grad():
        if model_type == "teacher":
            pt_outputs = pytorch_model(*sample_inputs)
        else: # student
            pt_outputs = pytorch_model(sample_inputs[1], sample_inputs[2])
    
    # --- ONNX Runtime æ¨ç† ---
    sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
    
    if model_type == "teacher":
        onnx_inputs = {
            "x_acc": sample_inputs[0].cpu().numpy(),
            "x_att_continuous": sample_inputs[1].cpu().numpy(),
            "x_att_discrete": sample_inputs[2].cpu().numpy()
        }
    else: # student
        onnx_inputs = {
            "x_att_continuous": sample_inputs[1].cpu().numpy(),
            "x_att_discrete": sample_inputs[2].cpu().numpy()
        }
    
    onnx_outputs = sess.run(None, onnx_inputs)
    
    # --- æ‰“å°æ¯”è¾ƒè¾“å‡º ---
    print("  æ‰“å°PyTorchå’ŒONNXçš„è¾“å‡º(åªçœ‹ä¸‰ä¸ªéƒ¨ä½æŸä¼¤å€¼è¾“å‡º, å¿½ç•¥ç¼–ç å™¨è§£ç å™¨ç‰¹å¾è¾“å‡º):")
    output_names = ["é¢„æµ‹å€¼(HIC,Dmax,Nij)"]
    np.set_printoptions(suppress=True, precision=6) # è®¾ç½®numpyæ‰“å°é€‰é¡¹ é¿å…ç§‘å­¦è®¡æ•°æ³•
    for i, name in enumerate(output_names):
        pt_out, onnx_out = pt_outputs[i].cpu().numpy(), onnx_outputs[i]
        print(f"  - {name}:")
        print(f"    PyTorch è¾“å‡º: {pt_out.flatten()} ")
        print(f"    ONNX è¾“å‡º:    {onnx_out.flatten()}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å¯¼å‡ºæ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹ä¸ºONNXæ ¼å¼ï¼Œå¹¶è¿›è¡ŒéªŒè¯")
    parser.add_argument("--teacher_run_dir", type=str, required=True, help="æ•™å¸ˆæ¨¡å‹è®­ç»ƒç›®å½•")
    parser.add_argument("--student_run_dir", type=str, default=None, help="å­¦ç”Ÿæ¨¡å‹è®­ç»ƒç›®å½•ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--teacher_weight", type=str, default="best_mais_accu.pth", help="æ•™å¸ˆæ¨¡å‹æƒé‡æ–‡ä»¶å")
    parser.add_argument("--student_weight", type=str, default="best_mais_accu.pth", help="å­¦ç”Ÿæ¨¡å‹æƒé‡æ–‡ä»¶å")
    parser.add_argument("--output_dir", type=str, default="./onnx_models", help="ONNXæ¨¡å‹è¾“å‡ºç›®å½•")
    parser.add_argument("--processor_path", type=str, default="./data/preprocessors.joblib", help="è¾“å…¥æ•°æ®çš„é¢„å¤„ç†å™¨æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--opset_version", type=int, default=17, help="ONNX opsetç‰ˆæœ¬")
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    device = torch.device('cpu') # ONNXå¯¼å‡ºå’ŒéªŒè¯å»ºè®®åœ¨CPUä¸Šè¿›è¡Œä»¥ä¿è¯ä¸€è‡´æ€§

    # 1. åŠ è½½é¢„å¤„ç†å™¨
    print(f"åŠ è½½é¢„å¤„ç†å™¨: {args.processor_path}")
    if not os.path.exists(args.processor_path):
        raise FileNotFoundError("é”™è¯¯: é¢„å¤„ç†å™¨æ–‡ä»¶ 'preprocessors.joblib' ä¸å­˜åœ¨ã€‚\n"
                              "è¯·å…ˆè¿è¡Œ 'dataset_prepare.py' è„šæœ¬æ¥ç”Ÿæˆæ­¤æ–‡ä»¶ã€‚")
    processor = joblib.load(args.processor_path)
    
    # 2. åˆ›å»ºå¹¶é¢„å¤„ç†ä¸€ä¸ªæ ·æœ¬è¾“å…¥
    print("\nåˆ›å»ºå¹¶é¢„å¤„ç†æ ·æœ¬è¾“å…¥...")
    raw_inputs = {
        "impact_velocity": 50,
        "impact_angle": 0,
        "overlap": 0.5,
        "occupant_type": 1,
        "ll1": 5.0,
        "ll2": 3.0,
        "btf": 50,
        "pp": 70,
        "plp": 50,
        "lla_status": 1,
        "llattf": 80,
        "dz": 2,
        "ptf": 57,
        "aft": 50,
        "aav_status": 1,
        "ttf": 70,
        "sp": 50,
        "recline_angle": 5,
        "waveform": -np.random.randn(3, 150) * 200  # å¯é€‰è‡ªå®šä¹‰æ³¢å½¢
    }
    raw_params, raw_waveform = create_sample_raw_input(raw_inputs)
    sample_inputs = preprocess_input(raw_params, raw_waveform, processor)
    
    # 3. åŠ è½½å¹¶å¯¼å‡ºæ•™å¸ˆæ¨¡å‹
    print("\n" + "="*50)
    print("å¤„ç†æ•™å¸ˆæ¨¡å‹")
    print("="*50)
    
    with open(os.path.join(args.teacher_run_dir, "TrainingRecord.json"), "r") as f:
        teacher_params = json.load(f)["hyperparameters"]["model"]
    
    # ä»é¢„å¤„ç†å™¨è·å–ç¦»æ•£ç‰¹å¾çš„ç±»åˆ«æ•°
    num_classes_of_discrete = [len(enc.classes_) for enc in processor.encoders_discrete]
    
    teacher_model = models.TeacherModel(**teacher_params, num_classes_of_discrete=num_classes_of_discrete).to(device)
    teacher_model.load_state_dict(torch.load(os.path.join(args.teacher_run_dir, args.teacher_weight), map_location=device))
    teacher_model.eval()
    
    teacher_onnx_path = os.path.join(args.output_dir, "TeacherModel.onnx")
    export_model(teacher_model, sample_inputs, teacher_onnx_path, "teacher", args.opset_version)
    verify_onnx_model(teacher_onnx_path, teacher_model, sample_inputs, "teacher")
    
    # 4. åŠ è½½å¹¶å¯¼å‡ºå­¦ç”Ÿæ¨¡å‹ (å¦‚æœæä¾›)
    if args.student_run_dir:
        print("\n" + "="*50)
        print("å¤„ç†å­¦ç”Ÿæ¨¡å‹")
        print("="*50)
        
        with open(os.path.join(args.student_run_dir, "TrainingRecord.json"), "r") as f:
            student_params = json.load(f)["hyperparameters"]["model"]
        
        student_model = models.StudentModel(**student_params, num_classes_of_discrete=num_classes_of_discrete).to(device)
        student_model.load_state_dict(torch.load(os.path.join(args.student_run_dir, args.student_weight), map_location=device))
        student_model.eval()
        
        student_onnx_path = os.path.join(args.output_dir, "StudentModel.onnx")
        export_model(student_model, sample_inputs, student_onnx_path, "student", args.opset_version)
        verify_onnx_model(student_onnx_path, student_model, sample_inputs, "student")

    print("\n" + "="*50)
    print("âœ” æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
    print(f"ONNX æ¨¡å‹å·²ä¿å­˜åœ¨: {args.output_dir}")
    print("="*50)